<!DOCTYPE html>
<!-- saved from url=(0042)http://home.ustc.edu.cn/~ll0825/index.html -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Lin Liu's Homepage</title>

  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta name="description" content="Lin Liu is currently a graduate student at USTC.">
  <meta name="keywords" content="Lin Liu, 刘林, liulin, lam lau  Huawei, USTC, Computer Vision, Low-level vision">
  <meta name="author" content="Lin Liu">

  <link rel="stylesheet" href="./Lin Liu&#39;s Homepage_files/w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/png" href="http://home.ustc.edu.cn/~ll0825/lamlau&#39;s%20Homepage_files/icons.png">

</head>


<body class="w3-content" style="max-width:1000px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-collapse w3-top w3-right" style="z-index:3;width:100px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h6><b>Welcome to liulin's home page.</b></h6>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="http://home.ustc.edu.cn/~ll0825/index.html#home" class="w3-bar-item w3-button">Home</a>
    <a href="http://home.ustc.edu.cn/~ll0825/index.html#news" class="w3-bar-item w3-button">News</a>
    <a href="http://home.ustc.edu.cn/~ll0825/index.html#projects" class="w3-bar-item w3-button">Projects</a>
    <a href="http://home.ustc.edu.cn/~ll0825/index.html#talks" class="w3-bar-item w3-button">Talks</a>
    <a href="http://home.ustc.edu.cn/~ll0825/index.html#publications" class="w3-bar-item w3-button">Research</a>
    <a href="http://home.ustc.edu.cn/~ll0825/index.html#service" class="w3-bar-item w3-button">Services</a>
    <a href="http://home.ustc.edu.cn/~ll0825/index.html#award" class="w3-bar-item w3-button">Awards</a>
    <a href="http://home.ustc.edu.cn/~ll0825/blogs.html" class="w3-bar-item w3-button">Blogs</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">LAMLAU</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right" style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home">
    	<img style="width: 80%;max-width: 320px" alt="profile photo" src="./Lin Liu&#39;s Homepage_files/photo2.png">
    	<h1>Lin Liu</h1>
	      <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px">
	       Currently, I am a Senior Reseacher in Huawei CBG AI Lab, leading a small group that mainly works on AIGC. Before that, I obtained PhD degree at University of Science and Technology of China (USTC) and Shanghai AI Laboratory. During my studied, I had internship experience at the Noah's Ark Lab (supervised by Jianzhuang Liu), ByteDance (supervised by <a href="https://scholar.google.com/citations?user=ccmIGVgAAAAJ&amp;hl=zh-CN">Qiubo Chen</a>), and Tencent (supervised remotely by <a href="https://liuquande.github.io/">Quande Liu</a>). I work closely with <a href="https://shanxinyuan.github.io/">Shanxin Yuan</a>, <a href="https://stephenjia.github.io/">Xu Jia</a>, <a href="https://lingxixie.com/Home.html">Lingxi Xie</a>, Mingming Zhao, and <a href="http://scholar.google.com/citations?user=61b6eYkAAAAJ&amp;hl=en">Prof. Qi Tian</a>.
	      </p>
        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px">
        If you are interested in intern/full-time positions of our group or any other collaboration with me, welcome to contact me via email. (如果对来我们团队实习或全职工作感兴趣，欢迎发送邮件联系我: [hwcbgailab, at, 163, dot, com])
        </p>
	      <p class="w3-center">
	       
                        <a href="https://github.com/laulampaul" style="color: blue">Github</a> &nbsp;/&nbsp;
	        <a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=aliP2WYAAAAJ" style="color: blue">Google Scholar</a> &nbsp;/&nbsp;
	        <a href="https://www.zhihu.com/people/a6e15fc4fc54002117c3f2dba289c19d" style="color: blue">Zhi Hu (知乎)</a>
	      </p>
        
  </div>

<!-- The education Section -->
  <div class="w3-container w3-padding-32" id="edu">
    <h2>Education</h2>
    <p></p><li> 2022 - 2024           <b>Graduate student (PhD)</b>, Department of Electronic Engineering and Information Science, <a href="https://www.ustc.edu.cn/">USTC (中国科学技术大学)</a>, supervised by Qi Tian, Yanfeng Wang, and Houqiang Li.</li><p></p>
    <p></p><li> 2019 - 2022            <b>Graduate student (Master)</b>, Department of Electronic Engineering and Information Science, <a href="https://www.ustc.edu.cn/">USTC (中国科学技术大学)</a>, supervised by Qi Tian, <a href="http://staff.ustc.edu.cn/~zhwg/index.html">Wengang Zhou</a> and Houqiang Li.</li><p></p>
    <p></p><li> 2015 - 2019    <b>Undergraduate student</b>, Department of Information Security from <a href="https://www.ustc.edu.cn/">USTC (中国科学技术大学)</a>, supervised by <a href="http://staff.ustc.edu.cn/~qling/">Qiang Ling</a>.</li><p></p>
 </div>

<!-- The News Section -->
  <h2> &nbsp; News</h2>
  <div class="w3-container w3-light-grey w3-padding-32" id="news" style="overflow: scroll; height: 200px;">
	  <p></p><li> Nov.2025 - One paper has been accepted by AAAI 2026, see you in Singapore !</li><p></p>
	  <p></p><li>Welcome to follow our latest AIGC paper O-Disco-edit , Bind-your-avatar, MEPG and RASA !!</li><p></p>
	  <p></p><li>Feb.2024 -   One paper has been accepted by TCSVT 2025 ! </li><p></p>
    <p></p><li>Feb.2024 -   One paper has been accepted by TMM 2024 ! </li><p></p>
   <p></p><li>Nov.2022 -   One paper has been accepted by AAAI 2023 ! </li><p></p>
    <p></p><li>Nov.2022 -   One paper has been accepted by TCSVT 2022 ! </li><p></p>
   <p></p><li>Apr.2022 -   We get the 5th place in the Night Photography Rendering Challenge and 3rd place in the HDR Challenge in <a href="https://data.vision.ee.ethz.ch/cvl/ntire22/"></a>NTIRE 22 !</li><p></p>
   <p></p><li>Dec.2021 -   One paper has been accepted by AAAI 2022 !</li><p></p>
    <p></p><li>Sep.2021 -   One paper has been accepted by TPAMI 2021 !</li><p></p>
     <p></p><li> Aug.2021 - We take the second place on ByteDance Camp 2021.</li><p></p>
     <p></p><li> Oct.2020 -  I obtain the National Scholarship of China for guaduate students.</li><p></p>
      <p></p><li> Sep.2020 - One paper has been accepted by <a href="https://nips.cc/Conferences/2020">NeurIPS 2020</a> !</li><p></p>
      <p></p><li> Sep. 2020 - I join EI Innovation Lab, Cloud BU, Huawei as a student research intern.</li><p></p>
      <p></p><li> Jul. 2020 - One paper has been accepted by <a href="https://eccv2020.eu/accepted-papers/">ECCV 2020</a>.</li><p></p> 
      <p></p><li> Feb. 2020 - One paper has been accepted by <a href="http://openaccess.thecvf.com/menu.py">CVPR 2020</a>.</li><p></p>
      <p></p><li> Dec. 2019 - Our image demoireing algorithm obtains a patent.</li><p></p>
      <p></p><li> Jun. 2019 - I obtain the excellent graduation thesis price of the USTC !</li><p></p>
      <p></p><li> Jan. 2019 - I join Huawei Noah's Ark Lab as a research intern.</li><p></p>
  </div>
   
  <div class="w3-container w3-padding-32" "="" id="publications">
    <h2>Publications</h2>
      <p class="w3-left-align" style="line-height:200%">
        My research interests include: 1) AIGC, 2) low-level vision and computational photography, 3) image/video or data compression, 4) Post-training of NLP, and 5) Neural radiance fields (NeRF).
        
      </p>

        <h4>Arxiv Papers</h4>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <!-- o disco edit  -->
            <tr bgcolor="#ffffff">
                <td style="padding:20px;width:35%;vertical-align:middle">
                    <img src="./Lin Liu&#39;s Homepage_files/odisco.png" width="250">
                </td>
                <td width="75%" valign="middle">
                    <p>
                        <a target="_blank" href="https://arxiv.org/abs/2506.19833">
                            <papertitle>O-DisCo-Edit: Object Distortion Control for Unified Realistic Video Editing</papertitle>
                        </a>
                        <br>
                        Yuqing Chen, Junjie Wang✉, Lin Liu✉, Ruihang Chu, Xiaopeng Zhang, Qi Tian, Yujiu Yang
                        <br>
                        <em>AAAI</em>, 2026
                        <br>
                        [<a target="_blank" href="https://arxiv.org/abs/2509.01596">paper</a>]
                        [<a target="_blank" href="https://cyqii.github.io/O-DisCo-Edit.github.io/">project</a>]
                    </p>
                </td>
            </tr>

			<tr bgcolor="#ffffff">
                <td style="padding:20px;width:35%;vertical-align:middle">
                    <img src="./Lin Liu&#39;s Homepage_files/mepg.png" width="250">
                </td>
                <td width="75%" valign="middle">
                    <p>
                        <a target="_blank" href="https://arxiv.org/abs/2506.19833">
                            <papertitle>MEPG: Multi-Expert Planning and Generation for Compositionally-Rich Image Generation</papertitle>
                        </a>
                        <br>
                        Yuan Zhao, Lin Liu✉
                        <br>
                        <em>arXiv preprint</em>, 2025
                        <br>
                        [<a target="_blank" href="https://arxiv.org/abs/2509.04126">paper</a>]
      
                    </p>
                </td>
            </tr>

			
            <!-- bind your  -->
            <tr bgcolor="#ffffff">
                <td style="padding:20px;width:35%;vertical-align:middle">
                    <img src="./Lin Liu&#39;s Homepage_files/bindyour.png" width="250">
                </td>
                <td width="75%" valign="middle">
                    <p>
                        <a target="_blank" href="https://arxiv.org/abs/2506.19833">
                            <papertitle>Bind-Your-Avatar: Multi-Talking-Character Video Generation with Dynamic 3D-mask-based Embedding Router</papertitle>
                        </a>
                        <br>
                        Yubo Huang, Weiqiang Wang, Sirui Zhao✉, Tong Xu, <b>Lin Liu</b>✉, Enhong Chen✉
                        <br>
                        <em>arXiv preprint</em>, 2025
                        <br>
                        [<a target="_blank" href="https://arxiv.org/abs/2506.19833">paper</a>]
                        [<a target="_blank" href="https://yubo-shankui.github.io/bind-your-avatar/">project</a>]
                    </p>
                </td>
            </tr>


            <!-- RASA -->
            <tr bgcolor="#ffffff">
                <td style="padding:20px;width:35%;vertical-align:middle">
                    <img src="./Lin Liu&#39;s Homepage_files/rasa.png" width="250">
                </td>
                <td width="75%" valign="middle">
                    <p>
                        <a target="_blank" href="https://arxiv.org/abs/2503.11571">
                            <papertitle>RASA: Replace Anyone, Say Anything – A Training-Free Framework for Audio-Driven and Universal Portrait Video Editing</papertitle>
                        </a>
                        <br>
                        Tianrui Pan*, <b>Lin Liu</b>✉, Jie Liu✉, Xiaopeng Zhang, Jie Tang, Gangshan Wu, Qi Tian
                        <br>
                        <em>arXiv preprint</em>, 2025
                        <br>
                        [<a target="_blank" href="https://arxiv.org/abs/2503.11571">paper</a>]
                        [<a target="_blank" href="https://alice01010101.github.io/RASA/">project</a>]
                    </p>
                </td>
            </tr>

            <!-- Text-Animator -->
            <tr bgcolor="#ffffff">
                <td style="padding:20px;width:35%;vertical-align:middle">
                    <img src="./Lin Liu&#39;s Homepage_files/text_animator.png" width="250">
                </td>
                <td width="75%" valign="middle">
                    <p>
                        <a target="_blank" href="https://export.arxiv.org/abs/2406.17777">
                            <papertitle>Text-Animator: Controllable Visual Text Video Generation</papertitle>
                        </a>
                        <br>
                        <b>Lin Liu</b>, Quande Liu, Shengju Qian, Yuan Zhou, Wengang Zhou, Houqiang Li, Lingxi Xie, Qi Tian
                        <br>
                        <em>arXiv preprint</em>, 2024
                        <br>
                        [<a target="_blank" href="https://export.arxiv.org/abs/2406.17777">paper</a>]
                        [<a target="_blank" href="https://laulampaul.github.io/text-animator.html">project</a>]
                        <br>
                        <i>Innovative framework for generating videos with dynamic visual text using text embedding injection and motion control modules</i>
                    </p>
                </td>
            </tr>

            <!-- Mask Sampling -->
            <tr bgcolor="#ffffff">
                <td style="padding:20px;width:35%;vertical-align:middle">
                    <img src="./Lin Liu&#39;s Homepage_files/mask_sampling.png" width="250">
                </td>
                <td width="75%" valign="middle">
                    <p>
                        <a target="_blank" href="https://arxiv.org/abs/2306.05704">
                            <papertitle>Exploring Effective Mask Sampling Modeling for Neural Image Compression</papertitle>
                        </a>
                        <br>
                        <b>Lin Liu</b>, Mingjie Zhao, Shanxin Yuan, Wei Lyu, Wengang Zhou, Houqiang Li, Yanfeng Wang, Qi Tian
                        <br>
                        <em>arXiv preprint</em>, 2023
                        <br>
                        [<a target="_blank" href="https://arxiv.org/abs/2306.05704">paper</a>]
                        [<a target="_blank" href="http://home.ustc.edu.cn/~ll0825/xx">code (coming soon)</a>]
                    </p>
                </td>
            </tr>
        </tbody>
    </table>

        <h4>Conference Papers</h4>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
                <!-- Low-Light Video Enhancement -->
                <tr bgcolor="#ffffff">
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <img src="./Lin Liu&#39;s Homepage_files/llve.png" width="250">
                    </td>
                    <td width="75%" valign="middle">
                        <p>
                            <a target="_blank" href="https://arxiv.org/abs/2208.11014">
                                <papertitle>Low-Light Video Enhancement with Synthetic Event Guidance</papertitle>
                            </a>
                            <br>
                            <b>Lin Liu</b>, Junfeng An, Jianzhuang Liu, Shanxin Yuan, Xiangyu Chen, Wengang Zhou, Houqiang Li, Yanfeng Wang, Qi Tian
                            <br>
                            <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2023
                            <br>
                            [<a target="_blank" href="https://arxiv.org/abs/2208.11014">paper</a>]
                            [<a target="_blank" href="https://gitee.com/mindspore/models/tree/master/research/cv/LLVE-SEG">code</a>]
                        </p>
                    </td>
                </tr>
    
                <!-- TAPE -->
                <tr bgcolor="#ffffff">
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <img src="./Lin Liu&#39;s Homepage_files/tape.png" width="250">
                    </td>
                    <td width="75%" valign="middle">
                        <p>
                            <a target="_blank" href="https://arxiv.org/abs/2203.06074v1">
                                <papertitle>TAPE: Task-Agnostic Prior Embedding for Image Restoration</papertitle>
                            </a>
                            <br>
                            <b>Lin Liu</b>, Lingxi Xie, Xiaopeng Zhang, Shanxin Yuan, Xiangyu Chen, Wengang Zhou, Houqiang Li, Qi Tian
                            <br>
                            <em>European Conference on Computer Vision (ECCV)</em>, 2022
                            <br>
                            [<a target="_blank" href="https://arxiv.org/abs/2203.06074v1">paper</a>]
                            [<a target="_blank" href="http://home.ustc.edu.cn/~ll0825/project_TAPE.html">project (code)</a>]
                        </p>
                    </td>
                </tr>
    
                <!-- SiamTrans -->
                <tr bgcolor="#ffffff">
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <img src="./Lin Liu&#39;s Homepage_files/siamtrans.png" width="250">
                    </td>
                    <td width="75%" valign="middle">
                        <p>
                            <a target="_blank" href="https://arxiv.org/abs/2112.09426">
                                <papertitle>SiamTrans: Zero-Shot Multi-Frame Image Restoration with Pre-Trained Siamese Transformers</papertitle>
                            </a>
                            <br>
                            <b>Lin Liu</b>, Shanxin Yuan, Jianzhuang Liu, Xin Guo, Youliang Yan, Qi Tian
                            <br>
                            <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2022
                            <br>
                            [<a target="_blank" href="https://arxiv.org/abs/2112.09426">paper</a>]
                        </p>
                    </td>
                </tr>
    
                <!-- FDNet -->
                <tr bgcolor="#ffffff">
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <img src="./Lin Liu&#39;s Homepage_files/FDNet.png" width="250">
                    </td>
                    <td width="75%" valign="middle">
                        <p>
                            <a target="_blank" href="https://arxiv.org/pdf/2011.02055.pdf">
                                <papertitle>Self-Adaptively Learning to Demoiré from Focused and Defocused Image Pairs</papertitle>
                            </a>
                            <br>
                            <b>Lin Liu</b>, Shanxin Yuan, Jianzhuang Liu, Liping Bao, Gregory Slabaugh, Qi Tian
                            <br>
                            <em>Neural Information Processing Systems (NeurIPS)</em>, 2020
                            <br>
                            [<a target="_blank" href="https://arxiv.org/pdf/2011.02055.pdf">paper</a>]
                            [<a target="_blank" href="https://github.com/laulampaul/demoireing_with_focused_and_defocused_images_pairs">code</a>]
                        </p>
                    </td>
                </tr>
    
                <!-- WDNet -->
                <tr bgcolor="#ffffff">
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <img src="./Lin Liu&#39;s Homepage_files/WDNet.png" width="250">
                    </td>
                    <td width="75%" valign="middle">
                        <p>
                            <a target="_blank" href="https://arxiv.org/abs/2007.07173">
                                <papertitle>Wavelet-Based Dual-Branch Network for Image Demoireing</papertitle>
                            </a>
                            <br>
                            <b>Lin Liu</b>, Jianzhuang Liu, Shanxin Yuan, Gregory Slabaugh, Ales Leonardis, Wengang Zhou, Qi Tian
                            <br>
                            <em>European Conference on Computer Vision (ECCV)</em>, 2020
                            <br>
                            [<a target="_blank" href="https://arxiv.org/abs/2007.07173">paper</a>]
                            [<a target="_blank" href="https://github.com/laulampaul/WDNet_demoire">code</a>]
                        </p>
                    </td>
                </tr>
    
                <!-- SGNet -->
                <tr bgcolor="#ffffff">
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <img src="./Lin Liu&#39;s Homepage_files/SGNet.png" width="250">
                    </td>
                    <td width="75%" valign="middle">
                        <p>
                            <a target="_blank" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_Joint_Demosaicing_and_Denoising_With_Self_Guidance_CVPR_2020_paper.pdf">
                                <papertitle>Joint Demosaicing and Denoising with Self Guidance</papertitle>
                            </a>
                            <br>
                            <b>Lin Liu</b>, Xu Jia, Jianzhuang Liu, Qi Tian
                            <br>
                            <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2020
                            <br>
                            [<a target="_blank" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_Joint_Demosaicing_and_Denoising_With_Self_Guidance_CVPR_2020_paper.pdf">paper</a>]
                            [<a target="_blank" href="https://github.com/laulampaul/sgnet">code</a>]
                        </p>
                    </td>
                </tr>
            </tbody>
        </table>
    
        <h4>Journal Papers</h4>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
                <!-- Video Demoireing -->
                <tr bgcolor="#ffffff">
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <img src="./Lin Liu&#39;s Homepage_files/videodemoiretmm.png" width="250">
                    </td>
                    <td width="75%" valign="middle">
                        <p>
                            <papertitle>Video Demoireing with Deep Temporal Color Embedding and Video-Image Invertible Consistency</papertitle>
                            <br>
                            <b>Lin Liu</b>, Junfeng An, Shanxin Yuan, Wengang Zhou, Houqiang Li, Yanfeng Wang, Qi Tian
                            <br>
                            <em>IEEE Transactions on Multimedia</em>, 2023
                            <br>
                            [<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/10445438/">paper</a>]
                        </p>
                    </td>
                </tr>

				<!-- Video Demoireing -->
                <tr bgcolor="#ffffff">
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <img src="./Lin Liu&#39;s Homepage_files/yuanzhou.jpg" width="250">
                    </td>
                    <td width="75%" valign="middle">
                        <p>
                            <papertitle>Controllable Relation Disentanglement for Few-Shot Class-Incremental Learning</papertitle>
                            <br>
                            Yuan Zhou, Richang Hong, Yanrong Guo, <b>Lin Liu</b>, Shijie Hao, Hanwang Zhang
                            <br>
                            <em>IEEE Transactions on Circuits and Systems for Video Technology</em>, 2023
                            <br>
                            [<a target="_blank" href="https://arxiv.org/pdf/2403.11070">paper</a>]
                        </p>
                    </td>
                </tr>

				<tr bgcolor="#ffffff">
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <img src="./Lin Liu&#39;s Homepage_files/scireport.jpg" width="250">
                    </td>
                    <td width="75%" valign="middle">
                        <p>
                            <papertitle>Joint Channel Estimation and Feedback with Masked Token Transformers in Massive MIMO Systems</papertitle>
                            <br>
                            Mei Yin, Mingming Zhao, <b>Lin Liu✉</b>, Lifu Liu
                            <br>
                            <em>Scientific Reports</em>, 2025
                            <br>
							[<a target="_blank" href="https://www.researchsquare.com/article/rs-6717894/v1">paper</a>]
                            
                        </p>
                    </td>
                </tr>
				
                <!-- Learning Frequency Domain -->
                <tr bgcolor="#ffffff">
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <img src="./Lin Liu&#39;s Homepage_files/mbcnn.png" width="250">
                    </td>
                    <td width="75%" valign="middle">
                        <p>
                            <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9547736">
                                <papertitle>Learning Frequency Domain Priors for Image Demoireing</papertitle>
                            </a>
                            <br>
                            Bolun Zheng, Shanxin Yuan, Chenggang Yan, Xiang Tian, Jiyong Zhang, Yaoqi Sun, <b>Lin Liu</b>, Ales Leonardis, Greg Slabaugh
                            <br>
                            <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em>, 2021
                            <br>
                            [<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9547736">paper</a>]
                            [<a target="_blank" href="https://github.com/zhenngbolun/Learnbale_Bandpass_Filter">code</a>]
                        </p>
                    </td>
                </tr>
            </tbody>
        </table>
    </div>



<!-- The Projects Section -->
  <div class="w3-container w3-padding-32" id="projects">
    <h2>Projects or Competitions</h2>
          <p></p><li>2022, the <b>5th place</b>, in the Night Photography Rendering Challenge in NTIRE 22</li><p></p>
          <p></p><li>2022, the <b>3rd place</b>, in the HDR Challenge in NTIRE 22</li><p></p>
          <p></p><li>08/2021, the <b>2nd place</b>, <a href="http://home.ustc.edu.cn/~ll0825/project_llve.html">Low light video enhancement using 3D curve estimation</a> at <a href="https://live.photoplus.cn/live/63034053?accessFrom=live#/list">ByteDance Summer Camp 2021</a> .</li><p></p>

          <p></p><li>10/2022, the <b>4th place</b>, <a href="http://home.ustc.edu.cn/~ll0825/project_wirelessmae.html"> FlowMat transformer</a> at <a href="https://www.datafountain.cn/competitions/574/ranking">the 3th Wireless AI Competition</a> .</li><p></p>

  </div>
  
  <!-- The Talks Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="talks">
    <h2>Talks</h2>
	   <p></p><li> 06/2021, "<a href="https://data.vision.ee.ethz.ch/cvl/ntire21/slides/cvpr_workshop-v3_Huawei_talk.pptx">Challenges and Solutions for Intelligent Image Restoration</a>" at <a href="https://data.vision.ee.ethz.ch/cvl/ntire21/">NTIRE 2021</a> .</li><p></p>
                   <p>Abstract: In recent years, with the development of deep learning, image restoration and enhancement, such as image denoising and image super-resolution, have attracted more and more attention. This talk will focus on the challenges faced by image restoration and propose some solutions: 1) For the problem that real data is difficult to obtain, we introduce methods of synthesizing more real data, self-supervised learning, and fine-tuning using pre-trained models. 2) For the existing models have limited in mining useful information, we first introduce the concept of ‘guidance restoration’, then introduce some self-guidance and external-guidance methods. 3) At last, we introduce some video or burst methods for image restoration.
                   </p>
	<!--    <p></p><li> 05/2020, "<a href=" "> Edge AI: Progress and Future Directions</a>" at <a href="https://www.qbitai.com/"> <strong>QbitAI</strong></a> using <a href="https://www.bilibili.com/"><strong>bilibili</strong></a>.</li><p></p>-->
  </div>
 <!-- The Publications Section -->

<div class="w3-container w3-padding-32" id="service">
    <h2>Collaborative Students & Interns</h2>
	<table>
          <tr>
            <td><b>Name</b></td>
            <td><b>Position</b></td>
            <td><b>Duration</b></td>
            <td><b>Background</b></td>
            <td><b>Next Station</b></td>
          </tr>
          <tr>
            <td><a href="https://openreview.net/profile?id=~Jiangtong_Tan1" target="_blank">Jiangtong Tan</a></td>
            <td>Research Intern</td>
            <td>2025 - now</td>
            <td>MSc student at USTC</td>
            <td> ---- </td>
          </tr>
          <tr>
            <td>Tianrui Pan</td>
            <td>Research Intern</td>
            <td>2024 - 2025</td>
            <td>PhD student at Nanjing University</td>
            <td> ---- </td>
          </tr>
          <tr>
            <td>Yan Li</td>
            <td>Research Intern</td>
            <td>2025 - now</td>
            <td>PhD student at HKUST </td>
            <td> ---- </td>
		  <tr>
            <td>Yuqing Chen</td>
            <td>Research Intern</td>
            <td>2025 - now</td>
            <td>PhD student at Tsinghua University</td>
            <td> ---- </td>
          </tr>
		  <tr>
            <td>Zhihan Xiao</td>
            <td>Research Intern</td>
            <td>2025 - now</td>
            <td>Master student at Tsinghua University</td>
            <td> ---- </td>
          </tr>
		  <tr>
            <td>Yubo Huang</td>
            <td>Collaborative student</td>
            <td>2025 - now</td>
            <td>Master student at USTC</td>
            <td> ---- </td>
          </tr>
		
		 <tr>
            <td>Yufei Liu</td>
            <td>Collaborative student</td>
            <td>2025 - now</td>
            <td>Master student at Xiamen University</td>
            <td> ---- </td>
          </tr>
		
		  <tr>
            <td>Yixin Gao</td>
            <td>Research Intern</td>
            <td>2025 - now</td>
            <td>PhD student at USTC</td>
            <td> ---- </td>
          </tr>    
        </table>
</div>

<!-- The Services Section -->
  <div class="w3-container w3-padding-32" id="service">
    <h2>Services</h2>
     <p></p><li> Reviewers of <a href="http://home.ustc.edu.cn/~ll0825/index.html">ICCV2021</a>, <a href="http://home.ustc.edu.cn/~ll0825/index.html">TOMM2021</a>, <a href="http://home.ustc.edu.cn/~ll0825/index.html">CVPR2022</a>, <a href="http://home.ustc.edu.cn/~ll0825/index.html">ECCV2022</a>,<a href="http://home.ustc.edu.cn/~ll0825/index.html">AAAI2023</a>, <a href="http://home.ustc.edu.cn/~ll0825/index.html">CVPR2023</a> <p></p>
      <!--<p></p><li> Senior Program Committee Members of <a href="">IJCAI 2020</a> and <a href="https://www.ijcai19.org/program-committee.html">IJCAI 2019</a>.<p></p>-->
      <!--<p></p></li><li> Program Committee Members of NeurIPS 2020, ICML 2020, ECCV 2020, CVPR 2020, ICLR 2020, AAAI 2020, ICCV 2019, CVPR 2019, ICLR 2019, AAAI 2019, IJCAI 2018, AAAI 2018, NeurIPS 2018, etc.<p></p>-->
  </li></div>

  <!-- The Awards Section -->
  <div class="w3-container  w3-light-grey w3-padding-32" id="award">
    <h2>Awards</h2>
     <p>2022.10 &nbsp;&nbsp;<b>Suzhou Yucai Scholarship (苏州育才奖学金) </b></p>
    <p>2019.09 &nbsp;&nbsp;<b>National Network Security Scholarship (国家网络安全奖学金) (<a href="http://cybersec.ustc.edu.cn/2019/0916/c15751a391425/page.htm" style="color: blue">link</a>)</b></p>
<p>2018.09 &nbsp;&nbsp;<b>National Scholarship (国家奖学金)</b> &nbsp;(highest national wide scholarship for students in China)</p>
<p>2019.09  &nbsp;&nbsp;<b>Outstanding Graduate Student of Anhui Province (安徽省优秀毕业生)</b></p> 
<p>2017.09  &nbsp;&nbsp;<b>Scholarship of Institute of electronics, Chinese Academy of Sciences (中国科学院电子所奖学金)</b></p> 
<p>2017.10  &nbsp;&nbsp;<b>中国科学技术大学机器人竞赛，第二名</b></p> 
  </div>  

  <!-- <div class="w3-light-grey w3-center w3-padding-24">
  	 Powered by <a href=" " title="W3.CSS" target="_blank" class="w3-hover-opacity">w3.css</a>.<br>
	<!-- Default Statcounter code for Lin Liu's Homepage
	https://home.ustc.edu.cn/~ll0825 -->
		
  </div>--&gt;

  <!-- End page content -->


<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>



</body></html>
